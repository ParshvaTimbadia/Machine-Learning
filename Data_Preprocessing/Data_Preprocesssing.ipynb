{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data_Preprocesssing.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kmoF7LS5cgh5",
        "colab_type": "text"
      },
      "source": [
        "**Importing the Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOAZcs21cp5k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aX4X_Y8n5TfN",
        "colab_type": "text"
      },
      "source": [
        "**Import DataSet** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJgTe9Ob5jOK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "3c161a2a-4c46-4284-ac67-1bb0b0dff412"
      },
      "source": [
        "dataset= pd.read_csv(\"Data.csv\")\n",
        "x= dataset.iloc[:, :-1].values\n",
        "y= dataset.iloc[:, -1].values\n",
        "\n",
        "print (x)\n",
        "print(y)\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['France' 44.0 72000.0]\n",
            " ['Spain' 27.0 48000.0]\n",
            " ['Germany' 30.0 54000.0]\n",
            " ['Spain' 38.0 61000.0]\n",
            " ['Germany' 40.0 nan]\n",
            " ['France' 35.0 58000.0]\n",
            " ['Spain' nan 52000.0]\n",
            " ['France' 48.0 79000.0]\n",
            " ['Germany' 50.0 83000.0]\n",
            " ['France' 37.0 67000.0]]\n",
            "['No' 'Yes' 'No' 'No' 'Yes' 'Yes' 'No' 'Yes' 'No' 'Yes']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDg_4DCKp3yp",
        "colab_type": "text"
      },
      "source": [
        "**Calculating the Missing Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNPAgKzdqBAD",
        "colab_type": "code",
        "outputId": "a8244bb5-b01c-4d8c-dbec-a1a8b26f2e91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
        "imp_mean.fit(x[:, 1:3])\n",
        "x[:, 1:3] =imp_mean.transform(x[:, 1:3])\n",
        "\n",
        "\n",
        "print (x)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['France' 44.0 72000.0]\n",
            " ['Spain' 27.0 48000.0]\n",
            " ['Germany' 30.0 54000.0]\n",
            " ['Spain' 38.0 61000.0]\n",
            " ['Germany' 40.0 63777.77777777778]\n",
            " ['France' 35.0 58000.0]\n",
            " ['Spain' 38.77777777777778 52000.0]\n",
            " ['France' 48.0 79000.0]\n",
            " ['Germany' 50.0 83000.0]\n",
            " ['France' 37.0 67000.0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ayb4t46RzWVF",
        "colab_type": "text"
      },
      "source": [
        "**Encoding Independent Variable**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyqbSHoDzfwC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "721d72f7-cbf9-4582-a4d7-4700579c770b"
      },
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "ct = ColumnTransformer([('encoder', OneHotEncoder(), [0])], remainder='passthrough')\n",
        "x = np.array(ct.fit_transform(x), dtype = np.str)\n",
        "\n",
        "print (x)\n",
        "\n",
        "#https://towardsdatascience.com/columntransformer-in-scikit-for-labelencoding-and-onehotencoding-in-machine-learning-c6255952731b\n",
        "#Use this link for better uniderstanding."
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['1.0' '0.0' '0.0' '44.0' '72000.0']\n",
            " ['0.0' '0.0' '1.0' '27.0' '48000.0']\n",
            " ['0.0' '1.0' '0.0' '30.0' '54000.0']\n",
            " ['0.0' '0.0' '1.0' '38.0' '61000.0']\n",
            " ['0.0' '1.0' '0.0' '40.0' '63777.77777777778']\n",
            " ['1.0' '0.0' '0.0' '35.0' '58000.0']\n",
            " ['0.0' '0.0' '1.0' '38.77777777777778' '52000.0']\n",
            " ['1.0' '0.0' '0.0' '48.0' '79000.0']\n",
            " ['0.0' '1.0' '0.0' '50.0' '83000.0']\n",
            " ['1.0' '0.0' '0.0' '37.0' '67000.0']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKnhL58W4rRn",
        "colab_type": "text"
      },
      "source": [
        "**Encoding Dependent Variable**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2A_-6hyc4wJh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6521a8d6-04c3-46ac-ad41-f8053b81019c"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "y= le.fit_transform(y)\n",
        "\n",
        "print (y)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1 0 0 1 1 0 1 0 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKHwgSlQ6bKU",
        "colab_type": "text"
      },
      "source": [
        "**Feature Scaling**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLIezaYG8eg9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "03106899-aecc-408f-c52b-aa9270f9914c"
      },
      "source": [
        "#What is Feature Scaling and Why ?\n",
        "# Feature Scaling is a technique to standardize the independent features present in the data in a fixed range. It is performed during the data pre-processing to handle highly varying magnitudes or values or units. If feature scaling is not done, then a machine learning algorithm tends to weigh greater values, higher and consider smaller values as the lower values, regardless of the unit of the values.\n",
        "\n",
        "# Example: If an algorithm is not using feature scaling method then it can consider the value 3000 meter to be greater than 5 km but thatâ€™s actually not true and in this case, the algorithm will give wrong predictions. So, we use Feature Scaling to bring all values to same magnitudes and thus, tackle this issue.\n",
        "\n",
        "# There are to ways to do Feature Scaling. 1> Standardisation and anothier is 2> Normalisation. \n",
        "\n",
        "# Here we are implementing Standardization as it is a bit more efficient. \n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "x = sc.fit_transform(x)\n",
        "\n",
        "print (x)\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 1.22474487e+00 -6.54653671e-01 -6.54653671e-01  7.58874362e-01\n",
            "   7.49473254e-01]\n",
            " [-8.16496581e-01 -6.54653671e-01  1.52752523e+00 -1.71150388e+00\n",
            "  -1.43817841e+00]\n",
            " [-8.16496581e-01  1.52752523e+00 -6.54653671e-01 -1.27555478e+00\n",
            "  -8.91265492e-01]\n",
            " [-8.16496581e-01 -6.54653671e-01  1.52752523e+00 -1.13023841e-01\n",
            "  -2.53200424e-01]\n",
            " [-8.16496581e-01  1.52752523e+00 -6.54653671e-01  1.77608893e-01\n",
            "   2.35783334e-16]\n",
            " [ 1.22474487e+00 -6.54653671e-01 -6.54653671e-01 -5.48972942e-01\n",
            "  -5.26656882e-01]\n",
            " [-8.16496581e-01 -6.54653671e-01  1.52752523e+00  8.88178420e-17\n",
            "  -1.07356980e+00]\n",
            " [ 1.22474487e+00 -6.54653671e-01 -6.54653671e-01  1.34013983e+00\n",
            "   1.38753832e+00]\n",
            " [-8.16496581e-01  1.52752523e+00 -6.54653671e-01  1.63077256e+00\n",
            "   1.75214693e+00]\n",
            " [ 1.22474487e+00 -6.54653671e-01 -6.54653671e-01 -2.58340208e-01\n",
            "   2.93712492e-01]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGdqYAsoTwku",
        "colab_type": "text"
      },
      "source": [
        "**Split Dataset into Test Set and Training Set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VK5Mpr0xUMWG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "0bda0bce-19f4-4dd1-c2fc-dd5080bfb4e3"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, y_train , x_test, y_test = train_test_split(x, y, test_size=0.2, random_state=0)\n",
        "\n",
        "print(x_train)\n",
        "print(y_train)\n",
        "print(x_test)\n",
        "print(y_test)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-8.16496581e-01  1.52752523e+00 -6.54653671e-01  1.77608893e-01\n",
            "   2.35783334e-16]\n",
            " [ 1.22474487e+00 -6.54653671e-01 -6.54653671e-01 -2.58340208e-01\n",
            "   2.93712492e-01]\n",
            " [-8.16496581e-01 -6.54653671e-01  1.52752523e+00 -1.71150388e+00\n",
            "  -1.43817841e+00]\n",
            " [-8.16496581e-01 -6.54653671e-01  1.52752523e+00  8.88178420e-17\n",
            "  -1.07356980e+00]\n",
            " [ 1.22474487e+00 -6.54653671e-01 -6.54653671e-01  1.34013983e+00\n",
            "   1.38753832e+00]\n",
            " [-8.16496581e-01 -6.54653671e-01  1.52752523e+00 -1.13023841e-01\n",
            "  -2.53200424e-01]\n",
            " [ 1.22474487e+00 -6.54653671e-01 -6.54653671e-01  7.58874362e-01\n",
            "   7.49473254e-01]\n",
            " [ 1.22474487e+00 -6.54653671e-01 -6.54653671e-01 -5.48972942e-01\n",
            "  -5.26656882e-01]]\n",
            "[[-0.81649658  1.52752523 -0.65465367 -1.27555478 -0.89126549]\n",
            " [-0.81649658  1.52752523 -0.65465367  1.63077256  1.75214693]]\n",
            "[1 1 1 0 1 0 0 1]\n",
            "[0 0]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}